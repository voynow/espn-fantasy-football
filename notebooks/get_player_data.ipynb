{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e23c95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bed8520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 95.0.4638\n",
      "[WDM] - Get LATEST driver version for 95.0.4638\n",
      "[WDM] - Driver [C:\\Users\\voyno\\.wdm\\drivers\\chromedriver\\win32\\95.0.4638.54\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# create drivers, access indeede\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"https://fantasy.espn.com/football\")\n",
    "\n",
    "# access nav\n",
    "nav = driver.find_element(By.CLASS_NAME, 'global-nav-container')\n",
    "sub_navs = nav.find_elements(By.CLASS_NAME, 'sub')\n",
    "\n",
    "# search for correct link in nav\n",
    "for item in sub_navs:\n",
    "    nav_link = item.find_element(By.CLASS_NAME, 'link-text')\n",
    "    if nav_link.text == 'Scoring Leaders':\n",
    "        nav_link.click()\n",
    "        time.sleep(5)\n",
    "        break\n",
    "\n",
    "# find correct dropdowns\n",
    "dropdown_items = driver.find_elements(By.CLASS_NAME, \"dropdown__select\")\n",
    "for item in dropdown_items:\n",
    "    if \"NFL Week\" in item.text:\n",
    "        select = Select(item)\n",
    "        dropdown_items = item.text.split(\"\\n\")[3:]\n",
    "\n",
    "        # iterate over all weeks\n",
    "        # excluding first two dropdowns and possibly current week\n",
    "        week_dfs = []\n",
    "        week_idxs = []\n",
    "        colnames = \"\"\n",
    "        get_colnames = True\n",
    "        for dropdown in dropdown_items:\n",
    "            select.select_by_visible_text(dropdown)\n",
    "            tables = driver.find_elements(By.CLASS_NAME, \"Table\")\n",
    "\n",
    "            # iterate over first 20 pages\n",
    "            week_data = []\n",
    "            for i in range(20):\n",
    "\n",
    "                # iterate over all tables in page\n",
    "                for j, table in enumerate(tables):\n",
    "                    if get_colnames:\n",
    "                        colnames += table.find_element(By.CLASS_NAME, \"Table__sub-header\").text + \"\\n\"\n",
    "                    rows = table.find_element(By.CLASS_NAME, \"Table__TBODY\").find_elements(By.CLASS_NAME, 'Table__TR')\n",
    "\n",
    "                    # edge case for first table (remove injury indicator)\n",
    "                    if not j:\n",
    "                        table_data = []\n",
    "                        for row in rows:\n",
    "                            row_list = row.text.split(\"\\n\")\n",
    "                            if row_list[1] in ['D', 'O', 'Q', 'IR']:\n",
    "                                row_list.remove(row_list[1])\n",
    "                            table_data.append(row_list)\n",
    "\n",
    "                    # create concatenate new rows onto table_data, axis=1\n",
    "                    else:\n",
    "                        table_data = [table_row + row.text.split(\"\\n\") for table_row, row in zip(table_data, rows)]\n",
    "\n",
    "                # turn off find elements colnames and save data\n",
    "                if get_colnames:\n",
    "                    colnames = colnames.split(\"\\n\")[:-1]\n",
    "                get_colnames = False\n",
    "                week_data.append(pd.DataFrame(table_data, columns=colnames))\n",
    "\n",
    "                # go to next page\n",
    "                driver.find_element(By.CLASS_NAME, \"Pagination__Button--next\").click()\n",
    "\n",
    "            # collect data\n",
    "            week_dfs.append(pd.concat(week_data))\n",
    "            week_idxs.append(int(dropdown[-1]))\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "974f984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode week number\n",
    "week_dfs = week_dfs[::-1]\n",
    "for i in range(len(week_dfs)):\n",
    "    week_dfs[i][\"week\"] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a477db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat data, remove players who score 0 points\n",
    "df = pd.concat(week_dfs)\n",
    "\n",
    "# Remove Bye week data, FA players, and players with no fpts score\n",
    "df = df[df[\"OPP\"] != \"*BYE*\"]\n",
    "df = df[df[\"OPP\"] != \"--\"]\n",
    "df = df[df['FPTS'] != \"--\"]\n",
    "\n",
    "\n",
    "# Remove @, fix 0 data, make dtype float\n",
    "df['OPP'] = df['OPP'].apply(lambda x: x.replace('@', ''))\n",
    "df['FPTS'] = df['FPTS'].astype('float')\n",
    "\n",
    "# reset index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# save data\n",
    "df.to_csv(\"data/player_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
